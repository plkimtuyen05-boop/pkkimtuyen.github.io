{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f94067-093f-4375-b8b0-ae5a150f624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Data columns (total 38 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Gender  199 non-null    object\n",
      " 1   Age     199 non-null    object\n",
      " 2   Income  199 non-null    object\n",
      " 3   Edu     199 non-null    object\n",
      " 4   TOUI    199 non-null    int64 \n",
      " 5   ST1     199 non-null    int64 \n",
      " 6   ST2     199 non-null    int64 \n",
      " 7   ST3     199 non-null    int64 \n",
      " 8   ST4     199 non-null    int64 \n",
      " 9   SQ1     199 non-null    int64 \n",
      " 10  SQ2     199 non-null    int64 \n",
      " 11  SQ3     199 non-null    int64 \n",
      " 12  SQ4     199 non-null    int64 \n",
      " 13  SQ5     199 non-null    int64 \n",
      " 14  FOMO1   199 non-null    int64 \n",
      " 15  FOMO2   199 non-null    int64 \n",
      " 16  FOMO3   199 non-null    int64 \n",
      " 17  FOMO4   199 non-null    int64 \n",
      " 18  FOMO5   199 non-null    int64 \n",
      " 19  PU1     199 non-null    int64 \n",
      " 20  PU2     199 non-null    int64 \n",
      " 21  PU3     199 non-null    int64 \n",
      " 22  PU4     199 non-null    int64 \n",
      " 23  PU5     199 non-null    int64 \n",
      " 24  BE1     199 non-null    int64 \n",
      " 25  BE2     199 non-null    int64 \n",
      " 26  BE3     199 non-null    int64 \n",
      " 27  BE4     199 non-null    int64 \n",
      " 28  BE5     199 non-null    int64 \n",
      " 29  SE1     199 non-null    int64 \n",
      " 30  SE2     199 non-null    int64 \n",
      " 31  SE3     199 non-null    int64 \n",
      " 32  SE4     199 non-null    int64 \n",
      " 33  US1     199 non-null    int64 \n",
      " 34  US2     199 non-null    int64 \n",
      " 35  US3     199 non-null    int64 \n",
      " 36  US4     199 non-null    int64 \n",
      " 37  US5     199 non-null    int64 \n",
      "dtypes: int64(34), object(4)\n",
      "memory usage: 59.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gender    0\n",
       "Age       0\n",
       "Income    0\n",
       "Edu       0\n",
       "TOUI      0\n",
       "ST1       0\n",
       "ST2       0\n",
       "ST3       0\n",
       "ST4       0\n",
       "SQ1       0\n",
       "SQ2       0\n",
       "SQ3       0\n",
       "SQ4       0\n",
       "SQ5       0\n",
       "FOMO1     0\n",
       "FOMO2     0\n",
       "FOMO3     0\n",
       "FOMO4     0\n",
       "FOMO5     0\n",
       "PU1       0\n",
       "PU2       0\n",
       "PU3       0\n",
       "PU4       0\n",
       "PU5       0\n",
       "BE1       0\n",
       "BE2       0\n",
       "BE3       0\n",
       "BE4       0\n",
       "BE5       0\n",
       "SE1       0\n",
       "SE2       0\n",
       "SE3       0\n",
       "SE4       0\n",
       "US1       0\n",
       "US2       0\n",
       "US3       0\n",
       "US4       0\n",
       "US5       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file Excel\n",
    "data = pd.read_excel(\"data.xlsx\")\n",
    "data.rename(columns={\"SR4\": \"ST4\"}, inplace=True)\n",
    "\n",
    "# Xem 5 dòng đầu\n",
    "data.head()\n",
    "\n",
    "# Kiểm tra thông tin cơ bản\n",
    "data.info()\n",
    "\n",
    "# Kiểm tra giá trị thiếu\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a43abc4a-44bc-498a-809d-5a2a5607f6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8b75a-17e8-4a2f-aecf-4a29e812bb5c",
   "metadata": {},
   "source": [
    "LÀM SẠCH DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd255899-215e-435c-836c-d43605e26994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Data columns (total 38 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Gender  199 non-null    object\n",
      " 1   Age     199 non-null    object\n",
      " 2   Income  199 non-null    object\n",
      " 3   Edu     199 non-null    object\n",
      " 4   TOUI    199 non-null    int64 \n",
      " 5   ST1     199 non-null    int64 \n",
      " 6   ST2     199 non-null    int64 \n",
      " 7   ST3     199 non-null    int64 \n",
      " 8   ST4     199 non-null    int64 \n",
      " 9   SQ1     199 non-null    int64 \n",
      " 10  SQ2     199 non-null    int64 \n",
      " 11  SQ3     199 non-null    int64 \n",
      " 12  SQ4     199 non-null    int64 \n",
      " 13  SQ5     199 non-null    int64 \n",
      " 14  FOMO1   199 non-null    int64 \n",
      " 15  FOMO2   199 non-null    int64 \n",
      " 16  FOMO3   199 non-null    int64 \n",
      " 17  FOMO4   199 non-null    int64 \n",
      " 18  FOMO5   199 non-null    int64 \n",
      " 19  PU1     199 non-null    int64 \n",
      " 20  PU2     199 non-null    int64 \n",
      " 21  PU3     199 non-null    int64 \n",
      " 22  PU4     199 non-null    int64 \n",
      " 23  PU5     199 non-null    int64 \n",
      " 24  BE1     199 non-null    int64 \n",
      " 25  BE2     199 non-null    int64 \n",
      " 26  BE3     199 non-null    int64 \n",
      " 27  BE4     199 non-null    int64 \n",
      " 28  BE5     199 non-null    int64 \n",
      " 29  SE1     199 non-null    int64 \n",
      " 30  SE2     199 non-null    int64 \n",
      " 31  SE3     199 non-null    int64 \n",
      " 32  SE4     199 non-null    int64 \n",
      " 33  US1     199 non-null    int64 \n",
      " 34  US2     199 non-null    int64 \n",
      " 35  US3     199 non-null    int64 \n",
      " 36  US4     199 non-null    int64 \n",
      " 37  US5     199 non-null    int64 \n",
      "dtypes: int64(34), object(4)\n",
      "memory usage: 59.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.describe()\n",
    "data.isnull().sum()\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1136a6f-9101-4ec5-9dff-9d80db6bf04c",
   "metadata": {},
   "source": [
    "KIỂM ĐỊNH ĐỘ TIN CẬY THANG ĐO (Cronbach’s α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf170a6b-cf2d-4e9a-8dfd-a8c7fd7f64a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Nhóm: Scarcity  ( 9 items ) ===\n",
      "  Cronbach's alpha = 0.945\n",
      "  Item-total correlations:\n",
      "    ST1: 0.719\n",
      "    ST2: 0.770\n",
      "    ST3: 0.793\n",
      "    ST4: 0.783\n",
      "    SQ1: 0.785\n",
      "    SQ2: 0.787\n",
      "    SQ3: 0.786\n",
      "    SQ4: 0.823\n",
      "    SQ5: 0.816\n",
      "  Alpha if item deleted:\n",
      "    drop ST1: alpha = 0.942\n",
      "    drop ST2: alpha = 0.939\n",
      "    drop ST3: alpha = 0.938\n",
      "    drop ST4: alpha = 0.939\n",
      "    drop SQ1: alpha = 0.938\n",
      "    drop SQ2: alpha = 0.938\n",
      "    drop SQ3: alpha = 0.938\n",
      "    drop SQ4: alpha = 0.936\n",
      "    drop SQ5: alpha = 0.937\n",
      "\n",
      "=== Nhóm: FOMO  ( 5 items ) ===\n",
      "  Cronbach's alpha = 0.919\n",
      "  Item-total correlations:\n",
      "    FOMO1: 0.815\n",
      "    FOMO2: 0.814\n",
      "    FOMO3: 0.850\n",
      "    FOMO4: 0.718\n",
      "    FOMO5: 0.763\n",
      "  Alpha if item deleted:\n",
      "    drop FOMO1: alpha = 0.896\n",
      "    drop FOMO2: alpha = 0.896\n",
      "    drop FOMO3: alpha = 0.888\n",
      "    drop FOMO4: alpha = 0.915\n",
      "    drop FOMO5: alpha = 0.907\n",
      "\n",
      "=== Nhóm: PU  ( 5 items ) ===\n",
      "  Cronbach's alpha = 0.943\n",
      "  Item-total correlations:\n",
      "    PU1: 0.838\n",
      "    PU2: 0.876\n",
      "    PU3: 0.833\n",
      "    PU4: 0.870\n",
      "    PU5: 0.808\n",
      "  Alpha if item deleted:\n",
      "    drop PU1: alpha = 0.931\n",
      "    drop PU2: alpha = 0.924\n",
      "    drop PU3: alpha = 0.932\n",
      "    drop PU4: alpha = 0.925\n",
      "    drop PU5: alpha = 0.936\n",
      "\n",
      "=== Nhóm: BE  ( 5 items ) ===\n",
      "  Cronbach's alpha = 0.928\n",
      "  Item-total correlations:\n",
      "    BE1: 0.774\n",
      "    BE2: 0.840\n",
      "    BE3: 0.819\n",
      "    BE4: 0.819\n",
      "    BE5: 0.804\n",
      "  Alpha if item deleted:\n",
      "    drop BE1: alpha = 0.919\n",
      "    drop BE2: alpha = 0.906\n",
      "    drop BE3: alpha = 0.910\n",
      "    drop BE4: alpha = 0.910\n",
      "    drop BE5: alpha = 0.913\n",
      "\n",
      "=== Nhóm: SE  ( 4 items ) ===\n",
      "  Cronbach's alpha = 0.905\n",
      "  Item-total correlations:\n",
      "    SE1: 0.768\n",
      "    SE2: 0.807\n",
      "    SE3: 0.814\n",
      "    SE4: 0.760\n",
      "  Alpha if item deleted:\n",
      "    drop SE1: alpha = 0.884\n",
      "    drop SE2: alpha = 0.870\n",
      "    drop SE3: alpha = 0.867\n",
      "    drop SE4: alpha = 0.888\n",
      "\n",
      "=== Nhóm: US  ( 5 items ) ===\n",
      "  Cronbach's alpha = 0.901\n",
      "  Item-total correlations:\n",
      "    US1: 0.731\n",
      "    US2: 0.846\n",
      "    US3: 0.774\n",
      "    US4: 0.739\n",
      "    US5: 0.701\n",
      "  Alpha if item deleted:\n",
      "    drop US1: alpha = 0.885\n",
      "    drop US2: alpha = 0.860\n",
      "    drop US3: alpha = 0.876\n",
      "    drop US4: alpha = 0.886\n",
      "    drop US5: alpha = 0.891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bước 2: Cronbach's Alpha và phân tích item\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# giả sử data đã nạp và tên là `data`\n",
    "# xác nhận lại các nhóm biến (đã chỉnh ST4)\n",
    "scarcity_cols = ['ST1', 'ST2', 'ST3', 'ST4','SQ1', 'SQ2', 'SQ3', 'SQ4', 'SQ5']\n",
    "scarcity_time_cols = ['ST1', 'ST2', 'ST3', 'ST4']\n",
    "scarcity_quantity_cols = ['SQ1', 'SQ2', 'SQ3', 'SQ4', 'SQ5']\n",
    "fomo_cols     = ['FOMO1', 'FOMO2', 'FOMO3', 'FOMO4', 'FOMO5']\n",
    "pu_cols       = ['PU1', 'PU2', 'PU3', 'PU4', 'PU5']\n",
    "be_cols       = ['BE1', 'BE2', 'BE3', 'BE4', 'BE5']\n",
    "se_cols       = ['SE1', 'SE2', 'SE3', 'SE4']\n",
    "us_cols       = ['US1', 'US2', 'US3', 'US4', 'US5']\n",
    "\n",
    "groups = {\n",
    "    \"Scarcity\": scarcity_cols,\n",
    "    \"FOMO\": fomo_cols,\n",
    "    \"PU\": pu_cols,\n",
    "    \"BE\": be_cols,\n",
    "    \"SE\": se_cols,\n",
    "    \"US\": us_cols\n",
    "}\n",
    "\n",
    "def cronbach_alpha(df_items):\n",
    "    \"\"\"Cronbach's alpha bằng công thức: alpha = (N/(N-1))*(1 - sum(var_i)/var_total)\"\"\"\n",
    "    df = df_items.dropna(axis=0, how='any')  # loại hàng có missing nếu có\n",
    "    item_vars = df.var(axis=0, ddof=1)\n",
    "    total_var = df.sum(axis=1).var(ddof=1)\n",
    "    N = df.shape[1]\n",
    "    if N <= 1:\n",
    "        return np.nan\n",
    "    alpha = (N / (N - 1)) * (1 - item_vars.sum() / total_var)\n",
    "    return alpha\n",
    "\n",
    "def item_total_correlations(df_items):\n",
    "    \"\"\"Tính hệ số tương quan giữa từng item và tổng của các item còn lại (item-total)\"\"\"\n",
    "    res = {}\n",
    "    for col in df_items.columns:\n",
    "        others = df_items.drop(columns=[col]).sum(axis=1)\n",
    "        r = df_items[col].corr(others)\n",
    "        res[col] = r\n",
    "    return res\n",
    "\n",
    "def alpha_if_item_deleted(df_items):\n",
    "    \"\"\"Tính α nếu loại từng item\"\"\"\n",
    "    res = {}\n",
    "    for col in df_items.columns:\n",
    "        df2 = df_items.drop(columns=[col])\n",
    "        res[col] = cronbach_alpha(df2)\n",
    "    return res\n",
    "\n",
    "# Chạy cho từng nhóm và in kết quả\n",
    "for name, cols in groups.items():\n",
    "    print(\"=== Nhóm:\", name, \" (\", len(cols), \"items ) ===\")\n",
    "    # kiểm tra tồn tại các cột\n",
    "    missing_cols = [c for c in cols if c not in data.columns]\n",
    "    if missing_cols:\n",
    "        print(\"  Lỗi: thiếu cột trong dữ liệu:\", missing_cols)\n",
    "        print()\n",
    "        continue\n",
    "\n",
    "    df_grp = data[cols].astype(float)  # đảm bảo kiểu số\n",
    "    alpha = cronbach_alpha(df_grp)\n",
    "    print(f\"  Cronbach's alpha = {alpha:.3f}\")\n",
    "\n",
    "    # item-total correlations\n",
    "    itc = item_total_correlations(df_grp)\n",
    "    print(\"  Item-total correlations:\")\n",
    "    for k, v in itc.items():\n",
    "        print(f\"    {k}: {v:.3f}\")\n",
    "\n",
    "    # alpha if item deleted\n",
    "    a_del = alpha_if_item_deleted(df_grp)\n",
    "    print(\"  Alpha if item deleted:\")\n",
    "    for k, v in a_del.items():\n",
    "        print(f\"    drop {k}: alpha = {v:.3f}\")\n",
    "    print()\n",
    "#Kết luận Bước 2: Tất cả α > 0.9 → rất tốt, thang đo đáng tin cậy, không cần loại mục nào. Không có item nào làm tăng alpha nếu bị loại → giữ nguyên toàn bộ 38 câu hỏi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b3299c-547d-48cd-b1bb-f99e10f2e5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Nhóm: Scarcity ===\n",
      "  Cronbach's Alpha (CA): 0.945\n",
      "  Composite Reliability (CR): 0.978\n",
      "  Average Variance Extracted (AVE): 0.833\n",
      "\n",
      "=== Nhóm: FOMO ===\n",
      "  Cronbach's Alpha (CA): 0.919\n",
      "  Composite Reliability (CR): 0.971\n",
      "  Average Variance Extracted (AVE): 0.870\n",
      "\n",
      "=== Nhóm: PU ===\n",
      "  Cronbach's Alpha (CA): 0.943\n",
      "  Composite Reliability (CR): 0.979\n",
      "  Average Variance Extracted (AVE): 0.902\n",
      "\n",
      "=== Nhóm: BE ===\n",
      "  Cronbach's Alpha (CA): 0.928\n",
      "  Composite Reliability (CR): 0.974\n",
      "  Average Variance Extracted (AVE): 0.882\n",
      "\n",
      "=== Nhóm: SE ===\n",
      "  Cronbach's Alpha (CA): 0.905\n",
      "  Composite Reliability (CR): 0.968\n",
      "  Average Variance Extracted (AVE): 0.883\n",
      "\n",
      "=== Nhóm: US ===\n",
      "  Cronbach's Alpha (CA): 0.901\n",
      "  Composite Reliability (CR): 0.966\n",
      "  Average Variance Extracted (AVE): 0.849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import eigvals\n",
    "\n",
    "def composite_reliability_and_ave(df_items):\n",
    "    \"\"\"\n",
    "    Tính Composite Reliability (CR) và Average Variance Extracted (AVE)\n",
    "    Dựa trên ma trận tương quan và eigenvalues (theo hướng tiếp cận CFA).\n",
    "    \"\"\"\n",
    "    df = df_items.dropna()\n",
    "    corr_matrix = df.corr()\n",
    "\n",
    "    # Trích eigenvalues để ước lượng phương sai chung\n",
    "    eig_vals = eigvals(corr_matrix)\n",
    "    first_eig = np.real(eig_vals[0])\n",
    "\n",
    "    # Hệ số tải giả định (factor loading) ~ căn bậc hai của tương quan với nhân tố chung\n",
    "    loadings = np.sqrt(np.clip(df.corrwith(df.sum(axis=1)), 0, 1))\n",
    "\n",
    "    # Bình phương hệ số tải\n",
    "    load_sq = loadings ** 2\n",
    "\n",
    "    # Composite Reliability (CR) = (Σλ)² / [(Σλ)² + Σ(1−λ²)]\n",
    "    cr = (loadings.sum())**2 / ((loadings.sum())**2 + ((1 - load_sq).sum()))\n",
    "\n",
    "    # Average Variance Extracted (AVE) = Σ(λ²) / n\n",
    "    ave = load_sq.mean()\n",
    "\n",
    "    return cr, ave\n",
    "\n",
    "\n",
    "# Bổ sung tính CR và AVE cho từng nhóm\n",
    "for name, cols in groups.items():\n",
    "    print(\"=== Nhóm:\", name, \"===\")\n",
    "    df_grp = data[cols].astype(float).dropna()\n",
    "\n",
    "    alpha = cronbach_alpha(df_grp)\n",
    "    cr, ave = composite_reliability_and_ave(df_grp)\n",
    "\n",
    "    print(f\"  Cronbach's Alpha (CA): {alpha:.3f}\")\n",
    "    print(f\"  Composite Reliability (CR): {cr:.3f}\")\n",
    "    print(f\"  Average Variance Extracted (AVE): {ave:.3f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7183ce45-9da3-42cf-8aac-f28f7d28b639",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Scarcity', 'FOMO', 'PU', 'BE', 'SE', 'US'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutliers_influence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variance_inflation_factor\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Ví dụ: chọn các biến độc lập (thay bằng tên biến của Na)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m X = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mScarcity\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFOMO\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPU\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBE\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSE\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mUS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m X = sm.add_constant(X)  \u001b[38;5;66;03m# thêm cột hằng số\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Tính VIF\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['Scarcity', 'FOMO', 'PU', 'BE', 'SE', 'US'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Ví dụ: chọn các biến độc lập (thay bằng tên biến của Na)\n",
    "X = data[['Scarcity', 'FOMO', 'PU', 'BE', 'SE', 'US']]\n",
    "X = sm.add_constant(X)  # thêm cột hằng số\n",
    "\n",
    "# Tính VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "                   for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e30573-0c26-46fd-b7b1-b8334378de71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "947d681f-fe3e-4a51-abab-f02ed7cb5e3a",
   "metadata": {},
   "source": [
    "TẠO BIẾN TỔNG HỢP, PHÂN TÍCH MÔ TẢ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff44d3-6bf2-4aaf-8599-cd891047144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 3: Tạo biến tổng hợp\n",
    "data['Scarcity'] = data[['ST1','ST2','ST3','ST4','SQ1','SQ2','SQ3','SQ4','SQ5']].mean(axis=1)\n",
    "data['scarcity_time'] = data[['ST1','ST2','ST3','ST4']].mean(axis=1)\n",
    "data['scarcity_quantity'] = data[['SQ1','SQ2','SQ3','SQ4','SQ5']].mean(axis=1)\n",
    "data['FOMO'] = data[['FOMO1','FOMO2','FOMO3','FOMO4','FOMO5']].mean(axis=1)\n",
    "data['PU'] = data[['PU1','PU2','PU3','PU4','PU5']].mean(axis=1)\n",
    "data['BE'] = data[['BE1','BE2','BE3','BE4','BE5']].mean(axis=1)\n",
    "data['SE'] = data[['SE1','SE2','SE3','SE4']].mean(axis=1)\n",
    "data['US'] = data[['US1','US2','US3','US4','US5']].mean(axis=1)\n",
    "\n",
    "# Thống kê mô tả\n",
    "desc = data[['Scarcity','FOMO','PU','BE','SE','US']].describe().T\n",
    "print(desc)\n",
    "\n",
    "# (Tuỳ chọn) Vẽ boxplot để xem phân bố\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(data=data[['Scarcity','FOMO','PU','BE','SE','US']])\n",
    "plt.title(\"Distribution of Mean Scores Across Scales\", fontsize=13)\n",
    "plt.ylabel(\"Mean Value\")\n",
    "plt.savefig('Phân bố điểm trung bình các thang đo')\n",
    "plt.show()\n",
    "#Tất cả các thang đo đạt độ tin cậy cao (Cronbach’s alpha > 0.9) và dữ liệu mô tả ổn định → Không cần loại biến hay xử lý thêm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae51e38-d1ec-4cca-841f-222b63acf58b",
   "metadata": {},
   "source": [
    "PHÂN TÍCH NHÂN TỐ KHÁM PHÁ (EFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5aa83d-09d2-4386-a723-04fb2cddf9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install factor_analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbfdf8-0ce4-4e13-aecb-b6da5c3d3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo, calculate_bartlett_sphericity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077a9b8-114e-49d4-8644-b25059d34327",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ST1','ST2','ST3','ST4','SQ1','SQ2','SQ3','SQ4','SQ5',\n",
    "        'FOMO1','FOMO2','FOMO3','FOMO4','FOMO5',\n",
    "        'PU1','PU2','PU3','PU4','PU5',\n",
    "        'BE1','BE2','BE3','BE4','BE5',\n",
    "        'SE1','SE2','SE3','SE4',\n",
    "        'US1','US2','US3','US4','US5']\n",
    "data_factors = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9b7d0-7818-4bd3-b5d9-c2c68220f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra độ phù hợp của dữ liệu cho EFA\n",
    "kmo_all, kmo_model = calculate_kmo(data_factors)\n",
    "chi_square_value, p_value = calculate_bartlett_sphericity(data_factors)\n",
    "\n",
    "print(f\"KMO overall: {kmo_model}\")\n",
    "print(f\"Bartlett’s Test p-value: {p_value}\")\n",
    "#đọc kết quả: KMO > 0.6 → dữ liệu phù hợp để làm EFA. Bartlett’s Test p < 0.05 → các biến có tương quan, nên chạy EFA được."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9166d1-ae8a-4067-bc3b-c12fab9dc391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra eigenvalues để xác định số nhân tố nên giữ lại\n",
    "fa = FactorAnalyzer(rotation=None)\n",
    "fa.fit(data_factors)\n",
    "ev, v = fa.get_eigenvalues()\n",
    "\n",
    "# Hiển thị eigenvalues\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(range(1, data_factors.shape[1]+1), ev)\n",
    "plt.plot(range(1, data_factors.shape[1]+1), ev)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Factor')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.savefig('biểu đồ scree plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4f1e18-46bf-471b-a6e9-f874cad47494",
   "metadata": {},
   "source": [
    "Khi EFA xác định được 6 nhân tố, điều đó nghĩa là:\n",
    "Tập hợp các biến quan sát (câu hỏi trong bảng khảo sát) được gộp lại thành 6 nhóm chính.\n",
    "Các nhân tố khác (từ nhân tố thứ 7 trở đi) có Eigenvalue < 1, nên không đủ điều kiện để được giữ lại (vì chúng giải thích rất ít phương sai, < 1 biến gốc).\n",
    "Nói cách khác, mô hình ban đầu có thể có 6 thang đo lý thuyết, và EFA xác nhận đúng 6 nhóm là phù hợp — các nhóm khác (nếu có) chỉ là nhiễu, không có ý nghĩa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63c2b7-80e2-41e3-aa56-d6ae0f92c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "factors = data[['Scarcity', 'FOMO', 'PU', 'BE', 'SE', 'US']]\n",
    "\n",
    "# Tính ma trận tương quan Pearson\n",
    "corr_matrix = factors.corr(method='pearson')\n",
    "print(corr_matrix)\n",
    "\n",
    "# Vẽ biểu đồ heatmap để trực quan hoá\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Pearson Correlation Matrix\")\n",
    "plt.savefig(\"Ma trận tương quan Pearson giữa các nhân tố\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6673eed-86cd-43fb-88db-576f429715ef",
   "metadata": {},
   "source": [
    "PHÂN TÍCH HỒI QUY ĐA BIẾN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2327378e-9628-41ba-bf29-3f892a5e6fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d859d-28af-4d3e-9aa3-41647c1f5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Xác định biến độc lập và phụ thuộc\n",
    "X = data[['Scarcity', 'FOMO', 'PU', 'BE', 'SE']]\n",
    "y = data['US']\n",
    "\n",
    "# Thêm hằng số vào mô hình\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Chạy hồi quy tuyến tính đa biến\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# In kết quả\n",
    "print(model.summary())\n",
    "print ('Durbin–Watson = 1.921 → Không có tự tương quan phần dư (vì DW nằm trong khoảng 1.5–2.5).Kiểm định Jarque–Bera có p = 0.0009 < 0.05 → Phần dư hơi lệch chuẩn nhẹ, nhưng mức độ chấp nhận được. Cond. No. = 42.5 (< 100) → Không có vấn đề đa cộng tuyến nghiêm trọng.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c2306c-33b8-4ed3-aeb4-9d736c38958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pingouin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627330b2-965c-4e70-891b-1464009998f9",
   "metadata": {},
   "source": [
    "TÁC ĐỘNG GIÁN TIẾP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e432af1-74fe-4abd-a336-ea1675347b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "model_direct = smf.ols(\"US ~ Scarcity + FOMO\", data=data).fit()\n",
    "print(model_direct.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cfbe83-c4db-42f5-b3ee-42056e9bfbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_direct = smf.ols(\"US ~ Scarcity + PU\", data=data).fit()\n",
    "print(model_direct.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb75965-db8f-4e93-bd7c-02fad50f5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "import pandas as pd\n",
    "\n",
    "# Mediation Scarcity -> FOMO -> US\n",
    "med_fomo = pg.mediation_analysis(data=data, x='Scarcity', m='FOMO', y='US', \n",
    "                                alpha=0.05, n_boot=5000)\n",
    "print(\"=== Mediation: Scarcity -> FOMO -> US ===\")\n",
    "print(med_fomo)\n",
    "\n",
    "# Mediation Scarcity -> PU -> US\n",
    "med_pu = pg.mediation_analysis(data=data, x='Scarcity', m='PU', y='US',\n",
    "                               alpha=0.05, n_boot=5000)\n",
    "print(\"\\n=== Mediation: Scarcity -> PU -> US ===\")\n",
    "print(med_pu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec34553e-2818-4fa9-9a2a-59d83510408b",
   "metadata": {},
   "source": [
    "TÁC ĐỘNG TRỰC TIẾP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e876f9a-74e3-4ab8-bce9-79c8d86045b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scarcity ảnh hưởng trực tiếp đến US\n",
    "model_direct = smf.ols(\"US ~ Scarcity\", data=data).fit()\n",
    "print(model_direct.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babbae0e-84d5-4688-b8c4-4a778e3c5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scarcity, bE ảnh hưởng trực tiếp đến US\n",
    "model_direct = smf.ols(\"US ~ Scarcity + BE\", data=data).fit()\n",
    "print(model_direct.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669fcc49-3201-4ca9-8aa0-77d1256a0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scarcity, SE ảnh hưởng trực tiếp đến US\n",
    "model_direct = smf.ols(\"US ~ Scarcity + SE\", data=data).fit()\n",
    "print(model_direct.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d340b2-b0cb-444e-a748-4a4ab346bcfb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PHẦN BỔ SUNG: THỐNG KÊ MÔ TẢ BIẾN NHÂN KHẨU HỌC\n",
    "# ==============================================================================\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n\\n--- THỐNG KÊ MÔ TẢ BIẾN NHÂN KHẨU HỌC ---\")\n",
    "\n",
    "# Danh sách các biến nhân khẩu học dạng phân loại\n",
    "demographic_categorical_cols = ['Gender', 'Age', 'Income', 'Edu']\n",
    "\n",
    "# Lặp qua từng biến để tính tần suất và vẽ biểu đồ\n",
    "for col in demographic_categorical_cols:\n",
    "    print(f\"\\n--- Phân tích biến: {col} ---\")\n",
    "    \n",
    "    # In ra bảng tần suất và tỷ lệ\n",
    "    frequency_table = pd.DataFrame({\n",
    "        'Tần suất (Count)': data[col].value_counts(),\n",
    "        'Tỷ lệ (%)': data[col].value_counts(normalize=True).mul(100).round(2)\n",
    "    })\n",
    "    print(frequency_table)\n",
    "    \n",
    "    # Vẽ biểu đồ cột\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(y=data[col], order=data[col].value_counts().index, palette='viridis')\n",
    "    plt.title(f'Biểu đồ phân bố của biến {col}', fontsize=14)\n",
    "    plt.xlabel('Số lượng (Count)', fontsize=12)\n",
    "    plt.ylabel(col, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Thống kê mô tả cho biến định lượng TOUI (Time On Using Internet)\n",
    "print(\"\\n--- Phân tích biến: TOUI ---\")\n",
    "print(data['TOUI'].describe())\n",
    "\n",
    "# Vẽ biểu đồ histogram để xem phân bố của TOUI\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['TOUI'], kde=True, bins=15)\n",
    "plt.title('Biểu đồ phân bố của biến TOUI', fontsize=14)\n",
    "plt.xlabel('Giá trị', fontsize=12)\n",
    "plt.ylabel('Tần suất', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f160e9d0-0deb-419c-85a6-2dae7564d12a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PHẦN BỔ SUNG: TÍCH HỢP BIẾN NHÂN KHẨU HỌC VÀO MÔ HÌNH HỒI QUY (PHIÊN BẢN SỬA LỖI)\n",
    "# ==============================================================================\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\\n--- PHÂN TÍCH HỒI QUY MỚI (BAO GỒM BIẾN NHÂN KHẨU HỌC) ---\")\n",
    "\n",
    "# Bước 1: Mã hóa các biến phân loại thành các biến giả (dummy variables)\n",
    "# Thêm dtype=float để đảm bảo các cột mới được tạo ra là số\n",
    "data_encoded = pd.get_dummies(data, columns=['Gender', 'Age', 'Income', 'Edu'], drop_first=True, dtype=float)\n",
    "\n",
    "# Bước 2: Xác định các biến độc lập (X) và biến phụ thuộc (y)\n",
    "original_predictors = ['Scarcity', 'FOMO', 'PU', 'BE', 'SE']\n",
    "demographic_predictors = [col for col in data_encoded.columns if any(prefix in col for prefix in ['Gender_', 'Age_', 'Income_', 'Edu_'])]\n",
    "\n",
    "# Ép kiểu cho biến TOUI để đảm bảo nó là số, chuyển lỗi thành NaN\n",
    "data_encoded['TOUI'] = pd.to_numeric(data_encoded['TOUI'], errors='coerce')\n",
    "\n",
    "# Kết hợp tất cả các biến sẽ sử dụng trong mô hình\n",
    "X_full = data_encoded[original_predictors + demographic_predictors + ['TOUI']]\n",
    "y_full = data_encoded['US']\n",
    "\n",
    "# *** BƯỚC SỬA LỖI QUAN TRỌNG ***\n",
    "# 1. Gộp X và y lại để xử lý NaN đồng bộ\n",
    "model_data = pd.concat([y_full, X_full], axis=1)\n",
    "\n",
    "# 2. In ra số dòng TRƯỚC khi loại bỏ giá trị thiếu\n",
    "print(f\"Số lượng quan sát ban đầu: {len(model_data)}\")\n",
    "\n",
    "# 3. Xóa tất cả các hàng có chứa bất kỳ giá trị thiếu (NaN) nào\n",
    "#    Điều này đảm bảo mô hình sẽ không gặp lỗi và y, X luôn khớp nhau\n",
    "model_data.dropna(inplace=True)\n",
    "\n",
    "print(f\"Số lượng quan sát hợp lệ (sau khi xóa NaN): {len(model_data)}\")\n",
    "\n",
    "# 4. Tách lại y và X sau khi đã làm sạch\n",
    "y_clean = model_data['US']\n",
    "X_clean = model_data.drop('US', axis=1)\n",
    "\n",
    "# Kiểm tra lần cuối để chắc chắn tất cả các cột đã là số\n",
    "if (X_clean.dtypes == 'object').any():\n",
    "    print(\"\\nCẢNH BÁO: Vẫn còn cột 'object' trong dữ liệu. Vui lòng kiểm tra lại dữ liệu nguồn.\")\n",
    "    print(X_clean.dtypes[X_clean.dtypes == 'object'])\n",
    "else:\n",
    "    print(\"\\n✔️ Kiểm tra thành công: Tất cả các cột đầu vào cho mô hình đã là số.\")\n",
    "\n",
    "    # Bước 3: Thêm hằng số (intercept) vào mô hình\n",
    "    X_final = sm.add_constant(X_clean)\n",
    "\n",
    "    # Bước 4: Chạy mô hình hồi quy OLS với dữ liệu đã được làm sạch hoàn toàn\n",
    "    model_full = sm.OLS(y_clean, X_final).fit()\n",
    "\n",
    "    # Bước 5: In kết quả chi tiết của mô hình mới\n",
    "    print(model_full.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef0be0-1822-41b7-bfd5-07c593a8075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mã hóa biến nhân khẩu học\n",
    "data['Gender'] = data['Gender'].map({'Nam': 1, 'Nữ': 0})\n",
    "data['Age_cat'] = data['Age'].astype('category').cat.codes\n",
    "data['Income_cat'] = data['Income'].astype('category').cat.codes\n",
    "data['Edu_cat'] = data['Edu'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041c364-cfb8-405f-b8fb-dd84ea4f4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "for gender, subset in data.groupby('Gender'):\n",
    "    name = 'Nam' if gender == 1 else 'Nữ'\n",
    "    X = subset[['Scarcity', 'FOMO', 'PU', 'BE', 'SE']]\n",
    "    y = subset['US']\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    print(f\"\\n=== Kết quả hồi quy nhóm {name} ===\")\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80fab7e-0404-48c1-8061-df9df6f006b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat, subset in data.groupby('Age_cat'):\n",
    "    print(f\"\\n=== Nhóm tuổi: {subset['Age'].iloc[0]} ===\")\n",
    "    X = subset[['Scarcity', 'FOMO', 'PU', 'BE', 'SE']]\n",
    "    y = subset['US']\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92ea12-b37c-40f7-b738-fca28801d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_group_regression(df, group_col):\n",
    "    results = []\n",
    "    for group, data in df.groupby(group_col):\n",
    "        model = smf.ols('US ~ Scarcity + FOMO + PU + BE + SE', data=data).fit()\n",
    "        results.append({\n",
    "            'Nhóm': group,\n",
    "            'R²': round(model.rsquared, 3),\n",
    "            'Adj R²': round(model.rsquared_adj, 3),\n",
    "            'F_p': round(model.f_pvalue, 4),\n",
    "            'PU_coef': round(model.params['PU'], 3),\n",
    "            'PU_p': round(model.pvalues['PU'], 4),\n",
    "            'FOMO_coef': round(model.params['FOMO'], 3),\n",
    "            'FOMO_p': round(model.pvalues['FOMO'], 4),\n",
    "            'Scarcity_coef': round(model.params['Scarcity'], 3),\n",
    "            'Scarcity_p': round(model.pvalues['Scarcity'], 4),\n",
    "            'SE_coef': round(model.params['SE'], 3),\n",
    "            'SE_p': round(model.pvalues['SE'], 4),\n",
    "            'BE_coef': round(model.params['BE'], 3),\n",
    "            'BE_p': round(model.pvalues['BE'], 4),\n",
    "        })\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa4b40-1fa4-4f2c-8d08-9e846f49e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So sánh theo giới tính\n",
    "gender_results = run_group_regression(data, 'Gender')\n",
    "\n",
    "# So sánh theo độ tuổi\n",
    "age_results = run_group_regression(data, 'Age')\n",
    "\n",
    "# So sánh theo thu nhập\n",
    "income_results = run_group_regression(data, 'Income')\n",
    "print(\"=== So sánh theo giới tính ===\")\n",
    "print(gender_results)\n",
    "\n",
    "print(\"\\n=== So sánh theo độ tuổi ===\")\n",
    "print(age_results)\n",
    "\n",
    "print(\"\\n=== So sánh theo thu nhập ===\")\n",
    "print(income_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d0445-645a-4bf3-97ef-e8cc0171d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Nếu chưa có nhóm scarcity thì chạy dòng này\n",
    "if 'Scarcity_Group' not in data.columns:\n",
    "    data['Scarcity_Group'] = pd.qcut(data['Scarcity'], q=3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Tùy chọn 1: Biểu đồ tán xạ FOMO vs US (chia theo nhóm Scarcity)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=data, x='FOMO', y='US', hue='Scarcity_Group', palette='coolwarm', alpha=0.7)\n",
    "sns.regplot(data=data, x='FOMO', y='US', scatter=False, color='black', ci=None)\n",
    "plt.title('Relationship between FOMO and Impulsive Buying Intention (US)\\nGrouped by the Level of Perceived Scarcity')\n",
    "plt.xlabel('Level of FOMO')\n",
    "plt.ylabel('Impulsive Buying Intention (US)')\n",
    "plt.legend(title='Scarcity Level')\n",
    "plt.savefig('fomo đến us group')\n",
    "plt.show()\n",
    "\n",
    "# Tùy chọn 2: Biểu đồ tán xạ PU vs US (chia theo nhóm Scarcity)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=data, x='PU', y='US', hue='Scarcity_Group', palette='coolwarm', alpha=0.7)\n",
    "sns.regplot(data=data, x='PU', y='US', scatter=False, color='black', ci=None)\n",
    "plt.title('Relationship between Perceived Urgency (PU) and Impulsive Buying Intention (US)\\nGrouped by the Level of Perceived Scarcity')\n",
    "plt.xlabel('Level of PU')\n",
    "plt.ylabel('Impulsive Buying Intention (US)')\n",
    "plt.legend(title='Scarcity Level')\n",
    "plt.savefig('pu đến us group')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd3053-071c-4349-a79c-26286adcd16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    data,\n",
    "    vars=[\"FOMO\", \"PU\", \"US\", \"Scarcity\"],\n",
    "    hue=\"Scarcity_Group\",\n",
    "    palette=\"husl\",\n",
    "    diag_kind=\"kde\"\n",
    ")\n",
    "plt.suptitle(\"Pairwise Relationships between FOMO, PU, Scarcity, and Impulsive Buying\", y=1.02, fontsize=13, fontweight='bold')\n",
    "plt.savefig('pairwise')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce6894-1f04-40cb-bc9a-438c36c24c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2. Scatter + regression: FOMO vs US, colored by Scarcity, facet by Gender\n",
    "g = sns.lmplot(\n",
    "    data=data,\n",
    "    x='FOMO', y='US',\n",
    "    hue='Scarcity_Group',\n",
    "    col='Gender',\n",
    "    palette=['#4A90E2','#BDBDBD','#FF7043'],\n",
    "    height=4, aspect=1,\n",
    "    scatter_kws={'alpha':0.6, 's':50},\n",
    "    markers=['o','s','D'],\n",
    "    ci=95\n",
    ")\n",
    "g.fig.suptitle(\"FOMO vs Impulsive Buying (US) by Scarcity Level and Gender\", fontsize=14, y=1.02)\n",
    "plt.show()  # ✅ thêm dòng này\n",
    "plt.savefig(\"scatter_FOMO_US_by_Scarcity_Gender.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62c8c9-1f68-4ad5-aa2a-5125e41db17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2. Scatter + regression: FOMO vs US, colored by Scarcity, facet by Gender\n",
    "g = sns.lmplot(\n",
    "    data=data,\n",
    "    x='PU', y='US',\n",
    "    hue='Scarcity_Group',\n",
    "    col='Gender',\n",
    "    palette=['#4A90E2','#BDBDBD','#FF7043'],\n",
    "    height=4, aspect=1,\n",
    "    scatter_kws={'alpha':0.6, 's':50},\n",
    "    markers=['o','s','D'],\n",
    "    ci=95\n",
    ")\n",
    "g.fig.suptitle(\"PU vs Impulsive Buying (US) by Scarcity Level and Gender\", fontsize=14, y=1.02)\n",
    "plt.show()  # ✅ thêm dòng này\n",
    "plt.savefig(\"scatter_PU_US_by_Scarcity_Gender.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602fc939-1108-41bf-966b-09052055d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thư viện\n",
    "import pandas as pd\n",
    "\n",
    "# Giả sử file của bạn đã load thành DataFrame 'data'\n",
    "# data = pd.read_excel(\"data.xlsx\")\n",
    "\n",
    "# Thống kê tần suất và tỉ lệ phần trăm cho các biến nhân khẩu học\n",
    "demo_vars = ['Gender', 'Age', 'Edu', 'Income', 'TOUI']\n",
    "\n",
    "for var in demo_vars:\n",
    "    print(f\"\\n--- {var.upper()} ---\")\n",
    "    freq_table = data[var].value_counts(dropna=False)\n",
    "    percent_table = round(data[var].value_counts(normalize=True, dropna=False) * 100, 2)\n",
    "    summary_df = pd.DataFrame({'Count': freq_table, 'Percent (%)': percent_table})\n",
    "    print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502a141-3ba5-4dfd-b01d-71cd8790c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tables = {}\n",
    "for var in demo_vars:\n",
    "    freq = data[var].value_counts(dropna=False)\n",
    "    pct = data[var].value_counts(normalize=True, dropna=False)*100\n",
    "    summary_tables[var] = pd.DataFrame({'Count': freq, 'Percent': pct.round(2)})\n",
    "\n",
    "# Hiển thị tóm tắt tất cả trong 1 bảng gọn\n",
    "demo_summary = pd.concat(summary_tables, axis=0)\n",
    "demo_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a1678-1fd6-408d-a3c5-41669f2695cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz statsmodels pingouin\n",
    "# On some systems you also need the system graphviz:\n",
    "# apt-get install graphviz      # (Linux)\n",
    "# brew install graphviz         # (mac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d4aae-97cf-48c4-9328-a9e339371bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tạo khung hình\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 6)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# ======= Vẽ các ô (biến trong mô hình) =======\n",
    "ax.text(1, 3, \"Scarcity\\n(X)\", ha=\"center\", va=\"center\", fontsize=11,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.4\", fc=\"#cce5ff\", ec=\"#003366\"))\n",
    "\n",
    "ax.text(5, 3, \"FOMO\\n(Mediator 1)\", ha=\"center\", va=\"center\", fontsize=11,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.4\", fc=\"#d4edda\", ec=\"#155724\"))\n",
    "\n",
    "ax.text(9, 3, \"Purchase Intention\\n(Y)\", ha=\"center\", va=\"center\", fontsize=11,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.4\", fc=\"#f8d7da\", ec=\"#721c24\"))\n",
    "\n",
    "# ======= Vẽ thêm các biến kiểm soát hoặc ảnh hưởng phụ (nếu có) =======\n",
    "ax.text(5, 1, \"Perceived Usefulness\\n(Control Variable)\", ha=\"center\", va=\"center\", fontsize=10,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"#fff3cd\", ec=\"#856404\"))\n",
    "\n",
    "# ======= Vẽ các mũi tên =======\n",
    "# Đường chính (X -> M -> Y)\n",
    "ax.annotate(\"\", xy=(4, 3), xytext=(2, 3), arrowprops=dict(arrowstyle=\"->\", lw=2))\n",
    "ax.annotate(\"\", xy=(8, 3), xytext=(6, 3), arrowprops=dict(arrowstyle=\"->\", lw=2))\n",
    "# Đường trực tiếp X -> Y\n",
    "ax.annotate(\"\", xy=(8, 3.8), xytext=(2, 3.8), arrowprops=dict(arrowstyle=\"->\", lw=2, linestyle=\"dashed\"))\n",
    "# Đường phụ PU -> Y\n",
    "ax.annotate(\"\", xy=(8.5, 2.8), xytext=(5.7, 1.2), arrowprops=dict(arrowstyle=\"->\", lw=1.8, color=\"gray\"))\n",
    "\n",
    "# ======= Ghi nhãn hệ số =======\n",
    "ax.text(3, 3.2, \"a\", fontsize=12)\n",
    "ax.text(7, 3.2, \"b\", fontsize=12)\n",
    "ax.text(5, 4.0, \"c’\", fontsize=12)\n",
    "ax.text(7, 2.3, \"control\", fontsize=10, color=\"gray\")\n",
    "\n",
    "# ======= Tiêu đề =======\n",
    "plt.title(\"Conceptual Framework: OLS Regression and Mediation Model\", fontsize=13, fontweight=\"bold\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa34436-6e0e-454c-b22f-7b60be3c86aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f442a7-3d9b-4147-b6ca-90a14300286b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
